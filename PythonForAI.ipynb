{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3d5dff-0014-4a15-9590-bf50a7498346",
   "metadata": {},
   "source": [
    "# Module 1: Introduction to Python Programming\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### Python installation and environment setup\n",
    "#### Python interpreter and IDEs\n",
    "#### Basic syntax and indentation\n",
    "#### Comments and documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5609ca-5da6-4934-bc01-ec37b91c77bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create your first Python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1280cd-9269-46a7-96c9-bedd1978ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, AI World!\n",
      "Python version check:\n",
      "3.13.3 (v3.13.3:6280bb54784, Apr  8 2025, 10:47:54) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, AI World!\")\n",
    "print(\"Python version check:\")\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cbfaef-9227-41c8-ba11-7c4838a7aa8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Practice: Create a simple calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6492c42a-68b9-4cb2-8acd-ea23406edfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter first number:  10\n",
      "Enter second number:  0\n",
      "Choose operation (+, -, *, /):  /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Cannot divide by zero\n"
     ]
    }
   ],
   "source": [
    "num1 = float(input(\"Enter first number: \"))\n",
    "num2 = float(input(\"Enter second number: \"))\n",
    "operation = input(\"Choose operation (+, -, *, /): \")\n",
    "\n",
    "if operation == '+':\n",
    "    result = num1 + num2\n",
    "elif operation == '-':\n",
    "    result = num1 - num2\n",
    "elif operation == '*':\n",
    "    result = num1 * num2\n",
    "elif operation == '/':\n",
    "    result = num1 / num2 if num2 != 0 else \"Cannot divide by zero\"\n",
    "\n",
    "print(f\"Result: {result}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12dcfaa-85c6-4150-bd15-fce93b2069d2",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "#### print(f\"Result: {result}\") creates an f-string (formatted string literal), which is a way to embed variables directly inside strings.\n",
    "#### result = num1 / num2 if num2 != 0 else \"Cannot divide by zero\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47f930-ffb0-424f-9e4a-91e01af7a846",
   "metadata": {},
   "source": [
    "# Project 1: AI Quote Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749f2407-02d3-435b-8425-f37b4de0ee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Quote of the Day:\n",
      "The question of whether a computer can think is no more interesting than the question of whether a submarine can swim. - Edsger Dijkstra\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ai_quotes = [\n",
    "    \"The question of whether a computer can think is no more interesting than the question of whether a submarine can swim. - Edsger Dijkstra\",\n",
    "    \"AI is likely to be either the best or worst thing to happen to humanity. - Stephen Hawking\",\n",
    "    \"Machine intelligence is the last invention that humanity will ever need to make. - Nick Bostrom\"\n",
    "]\n",
    "\n",
    "def generate_quote():\n",
    "    return random.choice(ai_quotes)\n",
    "\n",
    "print(\"AI Quote of the Day:\")\n",
    "print(generate_quote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848bf61b-e2e6-40cf-8c1b-9d839e49e577",
   "metadata": {},
   "source": [
    "# Module 2: Python Data Types and Operators\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### Numbers (int, float, complex)\n",
    "#### Strings and string methods\n",
    "#### Lists, tuples, sets, dictionaries\n",
    "#### Type conversion and checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbbc65-9107-4470-9bbc-6eca2c3a3f63",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Data Types for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2e7008-3f09-4438-ab89-517694921fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature: 24.48\n",
      "Word count: 5\n",
      "Model: Linear Regression, Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Numerical data (features in ML)\n",
    "temperature_readings = [23.5, 25.1, 22.8, 26.3, 24.7]\n",
    "print(f\"Average temperature: {sum(temperature_readings) / len(temperature_readings)}\")\n",
    "\n",
    "# String data (text processing)\n",
    "text_data = \"Natural Language Processing is fascinating\"\n",
    "words = text_data.lower().split()\n",
    "word_count = len(words)\n",
    "print(f\"Word count: {word_count}\")\n",
    "\n",
    "# Dictionary for structured data\n",
    "ml_model = {\n",
    "    \"name\": \"Linear Regression\",\n",
    "    \"accuracy\": 0.95,\n",
    "    \"features\": [\"age\", \"income\", \"education\"],\n",
    "    \"trained\": True\n",
    "}\n",
    "\n",
    "print(f\"Model: {ml_model['name']}, Accuracy: {ml_model['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db8be0-2a5e-406a-b21e-521134946608",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965e6db8-a461-43c4-8161-206a0641be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Name: Alice\n",
      "Student Grades Avg: 87.75\n",
      "Student Name: Bob\n",
      "Student Grades Avg: 83.5\n",
      "Student Name: Charlie\n",
      "Student Grades Avg: 92.5\n",
      "Data points: [('Alice', 87.75), ('Bob', 83.5), ('Charlie', 92.5)]\n"
     ]
    }
   ],
   "source": [
    "# Simulating a simple dataset\n",
    "student_grades = {\n",
    "    \"Alice\": [85, 92, 78, 96],\n",
    "    \"Bob\": [79, 85, 82, 88],\n",
    "    \"Charlie\": [92, 95, 89, 94]\n",
    "}\n",
    "\n",
    "# Calculate averages (like feature engineering)\n",
    "for student, grades in student_grades.items():\n",
    "    avg = sum(grades)/len(grades)\n",
    "    print(f\"Student Name: {student}\")\n",
    "    print(f\"Student Grades Avg: {avg}\")\n",
    "    \n",
    "# Convert to list of tuples (common data format)\n",
    "data_points = [(name, sum(grades)/len(grades)) for name, grades in student_grades.items()]\n",
    "print(\"Data points:\", data_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0e769-8e90-48d9-83e3-429793210de8",
   "metadata": {},
   "source": [
    "### Key Note\n",
    "#### Convert to list of tuples\n",
    "#### data_points = [(name, sum(grades)/len(grades)) for name, grades in student_grades.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b787758-4ecb-48df-aa4b-1093a5386039",
   "metadata": {},
   "source": [
    "### Project 2: Simple Data Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849f0f11-de06-445a-839e-5b9667d61cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10.00\n",
      "Sum: 32.70\n",
      "Mean: 3.27\n",
      "Min: 1.20\n",
      "Max: 5.60\n",
      "Range: 4.40\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset(data):\n",
    "    \"\"\"Analyze a list of numbers - common in AI preprocessing\"\"\"\n",
    "    if not data:\n",
    "        return \"No data provided\"\n",
    "    \n",
    "    stats = {\n",
    "        \"count\": len(data),\n",
    "        \"sum\": sum(data),\n",
    "        \"mean\": sum(data) / len(data),\n",
    "        \"min\": min(data),\n",
    "        \"max\": max(data),\n",
    "        \"range\": max(data) - min(data)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Test with sample data\n",
    "sample_data = [1.2, 3.4, 2.1, 5.6, 4.3, 2.8, 3.9, 1.7, 4.5, 3.2]\n",
    "results = analyze_dataset(sample_data)\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f\"{key.capitalize()}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86738d6-0a4c-4e9b-8d6e-5f3bd7fa1aae",
   "metadata": {},
   "source": [
    "#### In Python, not data evaluates to True when data is considered \"falsy\". Here are the values that are considered falsy:\n",
    "\n",
    "##### None\n",
    "##### Empty string: \"\"\n",
    "##### Empty list: []\n",
    "##### Empty dictionary: {}\n",
    "##### Empty tuple: ()\n",
    "##### Zero: 0 or 0.0\n",
    "##### Boolean False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1f9f0-0bf9-43be-b154-b714d7e3033b",
   "metadata": {},
   "source": [
    "#  Module 3: Conditional Statements and Loops\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### if, elif, else statements\n",
    "#### for and while loops\n",
    "#### Loop control (break, continue)\n",
    "#### Nested loops and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd05e4f-e29f-4020-8ab5-e2577a0571e7",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Decision Trees (AI Logic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "430e9f9a-0bb9-45f8-b739-f1d6b1fa8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature -5°C: Freezing\n",
      "Temperature 10°C: Cold\n",
      "Temperature 20°C: Moderate\n",
      "Temperature 30°C: Warm\n",
      "Temperature 40°C: Hot\n"
     ]
    }
   ],
   "source": [
    "def classify_temperature(temp):\n",
    "    \"\"\"Simple decision tree for temperature classification\"\"\"\n",
    "    if temp < 0:\n",
    "        return \"Freezing\"\n",
    "    elif temp < 15:\n",
    "        return \"Cold\"\n",
    "    elif temp < 25:\n",
    "        return \"Moderate\"\n",
    "    elif temp < 35:\n",
    "        return \"Warm\"\n",
    "    else:\n",
    "        return \"Hot\"\n",
    "\n",
    "# Test the classifier\n",
    "temperatures = [-5, 10, 20, 30, 40]\n",
    "for temp in temperatures:\n",
    "    print(f\"Temperature {temp}°C: {classify_temperature(temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088457-aef2-4285-a7e3-fc3948d05138",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "437b9f4c-174e-49cf-ad3e-33bd163a9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern Analysis:\n",
      "Pattern (1, 2): appears 3 times\n",
      "Pattern (2, 1): appears 1 times\n",
      "Pattern (2, 3): appears 2 times\n",
      "Pattern (3, 1): appears 2 times\n",
      "Pattern (3, 3): appears 1 times\n",
      "{(1, 2): 3, (2, 1): 1, (2, 3): 2, (3, 1): 2, (3, 3): 1}\n"
     ]
    }
   ],
   "source": [
    "def find_patterns(sequence):\n",
    "    \"\"\"Find repeating patterns in a sequence\"\"\"\n",
    "    patterns = {}\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        pair = (sequence[i], sequence[i+1])\n",
    "        if pair in patterns:\n",
    "            patterns[pair] += 1\n",
    "        else:\n",
    "            patterns[pair] = 1\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Analyze a sequence\n",
    "data_sequence = [1, 2, 1, 2, 3, 1, 2, 3, 3, 1]\n",
    "patterns = find_patterns(data_sequence)\n",
    "\n",
    "print(\"Pattern Analysis:\")\n",
    "for pattern, count in patterns.items():\n",
    "    print(f\"Pattern {pattern}: appears {count} times\")\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce8e5d-e7f6-4181-86a3-8033a99df80c",
   "metadata": {},
   "source": [
    "### Project 3: Simple Recommendation System RR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3e87d-f3f5-4b58-b91b-03da46020352",
   "metadata": {},
   "source": [
    "def recommend_content(user_preferences, available_content):\n",
    "    \"\"\"Basic content recommendation based on preferences\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    for content in available_content:\n",
    "        score = 0\n",
    "        for preference in user_preferences:\n",
    "            if preference.lower() in content[\"tags\"]:\n",
    "                score += 1\n",
    "        \n",
    "        if score > 0:\n",
    "            content_with_score = content.copy()\n",
    "            content_with_score[\"relevance_score\"] = score\n",
    "            recommendations.append(content_with_score)\n",
    "    \n",
    "    # Sort by relevance score\n",
    "    recommendations.sort(key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "    return recommendations\n",
    "\n",
    "# Sample data\n",
    "user_prefs = [\"AI\", \"Machine Learning\", \"Python\"]\n",
    "content_library = [\n",
    "    {\"title\": \"Introduction to AI\", \"tags\": [\"ai\", \"beginner\"]},\n",
    "    {\"title\": \"Python for Data Science\", \"tags\": [\"python\", \"data science\"]},\n",
    "    {\"title\": \"Machine Learning Basics\", \"tags\": [\"machine learning\", \"ai\"]},\n",
    "    {\"title\": \"Web Development\", \"tags\": [\"html\", \"css\", \"javascript\"]}\n",
    "]\n",
    "\n",
    "recommendations = recommend_content(user_prefs, content_library)\n",
    "print(\"Recommended Content:\")\n",
    "for item in recommendations:\n",
    "    print(f\"- {item['title']} (Score: {item['relevance_score']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddc5a2-ee3c-4eff-a2e9-1d7ed4377814",
   "metadata": {},
   "source": [
    "# Module 4: Python Functions\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### Function definition and calling\n",
    "#### Parameters and arguments\n",
    "#### Return statements\n",
    "#### Scope and lifetime\n",
    "#### Lambda functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb120c-3544-4f4a-92eb-afd629643c3d",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Mathematical Functions for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c2a9199-62e2-4c92-a455-f5e8b31c4df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function Results:\n",
      "x\tSigmoid\tReLU\n",
      "-2\t0.119\t0\n",
      "-1\t0.269\t0\n",
      "0\t0.500\t0\n",
      "1\t0.731\t1\n",
      "2\t0.881\t2\n",
      "\n",
      "Softmax([2.0, 1.0, 0.1]) = [0.659, 0.242, 0.099]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function used in neural networks\"\"\"\n",
    "    import math\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return max(0, x)\n",
    "\n",
    "def softmax(values):\n",
    "    \"\"\"Softmax function for multi-class classification\"\"\"\n",
    "    import math\n",
    "    exp_values = [math.exp(x) for x in values]\n",
    "    sum_exp = sum(exp_values)\n",
    "    return [x / sum_exp for x in exp_values]\n",
    "\n",
    "# Test activation functions\n",
    "test_values = [-2, -1, 0, 1, 2]\n",
    "print(\"Activation Function Results:\")\n",
    "print(\"x\\tSigmoid\\tReLU\")\n",
    "for x in test_values:\n",
    "    print(f\"{x}\\t{sigmoid(x):.3f}\\t{relu(x)}\")\n",
    "\n",
    "# Test softmax\n",
    "softmax_input = [2.0, 1.0, 0.1]\n",
    "softmax_output = softmax(softmax_input)\n",
    "print(f\"\\nSoftmax({softmax_input}) = {[round(x, 3) for x in softmax_output]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3318c04-2376-4720-9c90-33bc6454d845",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fd6cf12-5443-4c09-9e8b-815e205b6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [10, 20, 30, 40, 50]\n",
      "Normalized: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data):\n",
    "    \"\"\"Normalize data to 0-1 range (min-max scaling)\"\"\"\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    if range_val == 0:\n",
    "        return [0] * len(data) # creates and returns a list filled with zeros, where the number of zeros equals the length of the input data.\n",
    "    \n",
    "    return [(x - min_val) / range_val for x in data]\n",
    "\n",
    "def calculate_accuracy(predictions, actual):\n",
    "    \"\"\"Calculate accuracy of predictions\"\"\"\n",
    "    if len(predictions) != len(actual):\n",
    "        return 0\n",
    "    \n",
    "    correct = sum(1 for p, a in zip(predictions, actual) if p == a)\n",
    "    return correct / len(actual)\n",
    "\n",
    "# Test functions\n",
    "raw_data = [10, 20, 30, 40, 50]\n",
    "normalized = normalize_data(raw_data)\n",
    "print(f\"Original: {raw_data}\")\n",
    "print(f\"Normalized: {[round(x, 2) for x in normalized]}\")\n",
    "\n",
    "# Test accuracy\n",
    "pred = [1, 0, 1, 1, 0]\n",
    "actual = [1, 0, 0, 1, 0]\n",
    "acc = calculate_accuracy(pred, actual)\n",
    "print(f\"Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c106ff4-6a3b-4beb-b489-430ed4e23c66",
   "metadata": {},
   "source": [
    "#### correct = sum(1 for p, a in zip(predictions, actual) if p == a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb9898-3629-4a63-a9e0-dc0a612ca926",
   "metadata": {},
   "source": [
    "### Project 4: Feature Engineering Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed0f72df-3e48-4603-8edf-b77b19bf4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Features: {'word_count': 7, 'char_count': 52, 'sentence_count': 1, 'avg_word_length': 6.571428571428571}\n",
      "Polynomial features for x=3: [3, 9, 27]\n",
      "Binned data: [0, 0, 1, 2, 2, 0, 1, 2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def create_feature_engineering_toolkit():\n",
    "    \"\"\"Collection of feature engineering functions\"\"\"\n",
    "    \n",
    "    def extract_text_features(text):\n",
    "        \"\"\"Extract basic features from text\"\"\"\n",
    "        return {\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"char_count\": len(text),\n",
    "            \"sentence_count\": text.count('.') + text.count('!') + text.count('?'),\n",
    "            \"avg_word_length\": sum(len(word) for word in text.split()) / len(text.split()) if text.split() else 0\n",
    "        }\n",
    "    \n",
    "    def create_polynomial_features(x, degree=2):\n",
    "        \"\"\"Create polynomial features\"\"\"\n",
    "        features = [x]\n",
    "        for d in range(2, degree + 1):\n",
    "            features.append(x ** d)\n",
    "        return features\n",
    "    \n",
    "    def binning(data, num_bins=5):\n",
    "        \"\"\"Bin continuous data into categories\"\"\"\n",
    "        min_val, max_val = min(data), max(data)\n",
    "        bin_width = (max_val - min_val) / num_bins\n",
    "        \n",
    "        binned = []\n",
    "        for value in data:\n",
    "            bin_num = min(int((value - min_val) / bin_width), num_bins - 1)\n",
    "            binned.append(bin_num)\n",
    "        return binned\n",
    "    \n",
    "    return {\n",
    "        \"text_features\": extract_text_features,\n",
    "        \"polynomial\": create_polynomial_features,\n",
    "        \"binning\": binning\n",
    "    }\n",
    "\n",
    "# Test the toolkit\n",
    "toolkit = create_feature_engineering_toolkit()\n",
    "\n",
    "# Test text features\n",
    "sample_text = \"AI and machine learning are transforming technology.\"\n",
    "text_features = toolkit[\"text_features\"](sample_text)\n",
    "print(\"Text Features:\", text_features)\n",
    "\n",
    "# Test polynomial features\n",
    "poly_features = toolkit[\"polynomial\"](3, degree=3)\n",
    "print(\"Polynomial features for x=3:\", poly_features)\n",
    "\n",
    "# Test binning\n",
    "continuous_data = [1.2, 3.4, 5.6, 7.8, 9.1, 2.3, 4.5, 6.7, 8.9, 1.1]\n",
    "binned_data = toolkit[\"binning\"](continuous_data, num_bins=3)\n",
    "print(\"Binned data:\", binned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb9dc7-33bc-4cbf-8412-d0f8fc95b9b6",
   "metadata": {},
   "source": [
    "#### \"avg_word_length\": sum(len(word) for word in text.split()) / len(text.split()) if text.split() else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b19b4-2166-46d2-9ece-9214b01ef780",
   "metadata": {},
   "source": [
    "# Module 5: Object-Oriented Programming with Python\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### Classes and objects\n",
    "#### Attributes and methods\n",
    "#### Inheritance and polymorphism\n",
    "#### Encapsulation and abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b58dc-b10c-4840-b57e-d0e7259aec30",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Machine Learning Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af666551-fe86-4103-9725-d05c2580c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Linear Regression ---\n",
      "Training Linear Regression...\n",
      "Linear regression trained with coefficients: [0.5, -0.3, 0.8]\n",
      "Linear Regression accuracy: 91.98%\n",
      "\n",
      "--- Neural Network ---\n",
      "Training Neural Network...\n",
      "Training neural network with 3 layers\n",
      "Neural network training completed\n",
      "Neural Network accuracy: 83.24%\n"
     ]
    }
   ],
   "source": [
    "class MLModel:\n",
    "    \"\"\"Base class for machine learning models\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.is_trained = False\n",
    "        self.accuracy = 0.0\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        \"\"\"Train the model (placeholder)\"\"\"\n",
    "        print(f\"Training {self.name}...\")\n",
    "        self.is_trained = True\n",
    "        return f\"{self.name} training completed\"\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return \"Model not trained yet!\"\n",
    "        return f\"Predictions from {self.name}\"\n",
    "    \n",
    "    def evaluate(self, test_data, test_labels):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return \"Cannot evaluate untrained model\"\n",
    "        \n",
    "        # Simulate evaluation\n",
    "        import random\n",
    "        self.accuracy = random.uniform(0.7, 0.95)\n",
    "        return f\"{self.name} accuracy: {self.accuracy:.2%}\"\n",
    "\n",
    "class LinearRegression(MLModel):\n",
    "    \"\"\"Linear regression model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"Linear Regression\")\n",
    "        self.coefficients = []\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        super().train(training_data)\n",
    "        self.coefficients = [0.5, -0.3, 0.8]  # Simulated coefficients\n",
    "        return f\"Linear regression trained with coefficients: {self.coefficients}\"\n",
    "\n",
    "class NeuralNetwork(MLModel):\n",
    "    \"\"\"Neural network model\"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        super().__init__(\"Neural Network\")\n",
    "        self.layers = layers\n",
    "        self.weights = []\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        super().train(training_data)\n",
    "        print(f\"Training neural network with {len(self.layers)} layers\")\n",
    "        return \"Neural network training completed\"\n",
    "\n",
    "# Test the classes\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    NeuralNetwork([10, 5, 1])\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.name} ---\")\n",
    "    print(model.train(\"training_data\"))\n",
    "    print(model.evaluate(\"test_data\", \"test_labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1d600-0bd6-4c4c-ab98-8a8973913044",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa853482-80b4-47d1-b304-65709fba48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: {'size': 11, 'has_labels': False, 'sample': [1, 2, 3]}\n",
      "Starting with 11 data points\n",
      "After Remove Outliers: 10 data points\n",
      "After Normalize: 10 data points\n",
      "Final processed data: [0.0, 0.111, 0.222, 0.333, 0.444, 0.556, 0.667, 0.778, 0.889, 1.0]\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Data processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "        self.processed_data = None\n",
    "    \n",
    "    def add_step(self, step_function, step_name):\n",
    "        \"\"\"Add a processing step\"\"\"\n",
    "        self.steps.append({\"function\": step_function, \"name\": step_name})\n",
    "    \n",
    "    def process(self, data):\n",
    "        \"\"\"Execute all processing steps\"\"\"\n",
    "        current_data = data\n",
    "        print(f\"Starting with {len(data)} data points\")\n",
    "        \n",
    "        for step in self.steps:\n",
    "            current_data = step[\"function\"](current_data)\n",
    "            print(f\"After {step['name']}: {len(current_data)} data points\")\n",
    "        \n",
    "        self.processed_data = current_data\n",
    "        return current_data\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"Class to represent a dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.size = len(data)\n",
    "    \n",
    "    def split(self, train_ratio=0.8):\n",
    "        \"\"\"Split dataset into training and testing\"\"\"\n",
    "        split_point = int(len(self.data) * train_ratio)\n",
    "        \n",
    "        train_data = self.data[:split_point]\n",
    "        test_data = self.data[split_point:]\n",
    "        \n",
    "        train_labels = self.labels[:split_point] if self.labels else None\n",
    "        test_labels = self.labels[split_point:] if self.labels else None\n",
    "        \n",
    "        return (Dataset(train_data, train_labels), \n",
    "                Dataset(test_data, test_labels))\n",
    "    \n",
    "    def describe(self):\n",
    "        \"\"\"Describe the dataset\"\"\"\n",
    "        return {\n",
    "            \"size\": self.size,\n",
    "            \"has_labels\": self.labels is not None,\n",
    "            \"sample\": self.data[:3] if len(self.data) >= 3 else self.data\n",
    "        }\n",
    "\n",
    "# Test the data processing classes\n",
    "def remove_outliers(data):\n",
    "    \"\"\"Remove extreme values\"\"\"\n",
    "    mean = sum(data) / len(data)\n",
    "    std = (sum((x - mean) ** 2 for x in data) / len(data)) ** 0.5\n",
    "    return [x for x in data if abs(x - mean) <= 2 * std]\n",
    "\n",
    "def normalize(data):\n",
    "    \"\"\"Normalize data\"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    if max_val == min_val:\n",
    "        return data\n",
    "    return [(x - min_val) / (max_val - min_val) for x in data]\n",
    "\n",
    "# Create and use the pipeline\n",
    "raw_data = [1, 2, 3, 100, 4, 5, 6, 7, 8, 9, 10]  # Contains outlier\n",
    "dataset = Dataset(raw_data)\n",
    "\n",
    "print(\"Original dataset:\", dataset.describe())\n",
    "\n",
    "processor = DataProcessor()\n",
    "processor.add_step(remove_outliers, \"Remove Outliers\")\n",
    "processor.add_step(normalize, \"Normalize\")\n",
    "\n",
    "processed_data = processor.process(raw_data)\n",
    "print(\"Final processed data:\", [round(x, 3) for x in processed_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e75e9b-c528-40ab-914d-53c0e83a2dea",
   "metadata": {},
   "source": [
    "#### Key Note  train_data = self.data[:split_point],  test_data = self.data[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6bd97-e5b1-4712-9b77-f40adbf92e2f",
   "metadata": {},
   "source": [
    "### Project 5: AI Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4becee77-773b-4d63-b09b-7f959bb595aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ChatBot Test ---\n",
      "Hello! I'm Alice. How can I help you?\n",
      "I'm doing well, thank you! I've had 1 interactions.\n",
      "Chatbot experience: 2\n",
      "\n",
      "--- Recommendation Agent Test ---\n",
      "- Recommendation 1 based on AI, Python, Machine Learning\n",
      "- Recommendation 2 based on AI, Python, Machine Learning\n",
      "- Recommendation 3 based on AI, Python, Machine Learning\n"
     ]
    }
   ],
   "source": [
    "class AIAgent:\n",
    "    \"\"\"Base class for AI agents\"\"\"\n",
    "    \n",
    "    def __init__(self, name, capabilities=None):\n",
    "        self.name = name\n",
    "        self.capabilities = capabilities or []\n",
    "        self.memory = {}\n",
    "        self.experience = 0\n",
    "    \n",
    "    def perceive(self, environment):\n",
    "        \"\"\"Perceive the environment\"\"\"\n",
    "        return f\"{self.name} perceiving environment\"\n",
    "    \n",
    "    def think(self, perception):\n",
    "        \"\"\"Process perception and decide action\"\"\"\n",
    "        self.experience += 1\n",
    "        return \"thinking...\"\n",
    "    \n",
    "    def act(self, decision):\n",
    "        \"\"\"Execute an action\"\"\"\n",
    "        return f\"{self.name} executing: {decision}\"\n",
    "    \n",
    "    def learn(self, feedback):\n",
    "        \"\"\"Learn from feedback\"\"\"\n",
    "        self.memory[len(self.memory)] = feedback\n",
    "        return \"Learning completed\"\n",
    "\n",
    "class ChatBot(AIAgent):\n",
    "    \"\"\"Chatbot AI agent\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name, [\"text_processing\", \"conversation\"])\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def respond(self, user_input):\n",
    "        \"\"\"Generate response to user input\"\"\"\n",
    "        self.conversation_history.append((\"user\", user_input))\n",
    "        \n",
    "        # Simple response logic\n",
    "        if \"hello\" in user_input.lower():\n",
    "            response = f\"Hello! I'm {self.name}. How can I help you?\"\n",
    "        elif \"how are you\" in user_input.lower():\n",
    "            response = f\"I'm doing well, thank you! I've had {self.experience} interactions.\"\n",
    "        else:\n",
    "            response = f\"I understand you said: '{user_input}'. That's interesting!\"\n",
    "        \n",
    "        self.conversation_history.append((\"bot\", response))\n",
    "        self.experience += 1\n",
    "        return response\n",
    "\n",
    "class RecommendationAgent(AIAgent):\n",
    "    \"\"\"Recommendation system agent\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name, [\"recommendation\", \"data_analysis\"])\n",
    "        self.user_profiles = {}\n",
    "        self.item_database = []\n",
    "    \n",
    "    def add_user_preference(self, user_id, preferences):\n",
    "        \"\"\"Add user preferences\"\"\"\n",
    "        self.user_profiles[user_id] = preferences\n",
    "    \n",
    "    def recommend(self, user_id, num_recommendations=3):\n",
    "        \"\"\"Generate recommendations\"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            return \"User not found\"\n",
    "        \n",
    "        user_prefs = self.user_profiles[user_id]\n",
    "        # Simple recommendation logic\n",
    "        recommendations = [f\"Recommendation {i+1} based on {', '.join(user_prefs)}\" \n",
    "                         for i in range(num_recommendations)]\n",
    "        \n",
    "        self.experience += 1\n",
    "        return recommendations\n",
    "\n",
    "# Test the AI agents\n",
    "chatbot = ChatBot(\"Alice\")\n",
    "print(\"--- ChatBot Test ---\")\n",
    "print(chatbot.respond(\"Hello there!\"))\n",
    "print(chatbot.respond(\"How are you doing?\"))\n",
    "print(f\"Chatbot experience: {chatbot.experience}\")\n",
    "\n",
    "recommender = RecommendationAgent(\"RecBot\")\n",
    "print(\"\\n--- Recommendation Agent Test ---\")\n",
    "recommender.add_user_preference(\"user123\", [\"AI\", \"Python\", \"Machine Learning\"])\n",
    "recommendations = recommender.recommend(\"user123\")\n",
    "for rec in recommendations:\n",
    "    print(f\"- {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2853d-2fec-4abf-84a1-ae01194760c2",
   "metadata": {},
   "source": [
    "# Module 6: Threading and Multithreading\n",
    "\n",
    "### Theory Concepts:\n",
    "\n",
    "#### Thread basics and threading module\n",
    "#### Creating and managing threads\n",
    "#### Thread synchronization\n",
    "#### Parallel processing for AI tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f70ab51-14d7-452f-9267-6c86ff469a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0: Processing 25 items\n",
      "Thread 1: Processing 25 items\n",
      "Thread 2: Processing 25 items\n",
      "Thread 3: Processing 25 items\n",
      "Thread 0: Completed processingThread 3: Completed processing\n",
      "Thread 1: Completed processing\n",
      "\n",
      "Thread 2: Completed processing\n",
      "Parallel processing completed in 0.30 seconds\n",
      "Processed 100 items\n",
      "Sample results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "def process_data_chunk(chunk_id, data_chunk, results, lock):\n",
    "    \"\"\"Process a chunk of data in parallel\"\"\"\n",
    "    print(f\"Thread {chunk_id}: Processing {len(data_chunk)} items\")\n",
    "    \n",
    "    # Simulate data processing (e.g., feature extraction)\n",
    "    processed = []\n",
    "    for item in data_chunk:\n",
    "        # Simulate complex computation\n",
    "        time.sleep(0.01)  # Simulated processing time\n",
    "        processed_item = item ** 2  # Simple transformation\n",
    "        processed.append(processed_item)\n",
    "    \n",
    "    # Thread-safe result storage\n",
    "    with lock:\n",
    "        results[chunk_id] = processed\n",
    "    \n",
    "    print(f\"Thread {chunk_id}: Completed processing\")\n",
    "\n",
    "def parallel_data_processing(data, num_threads=4):\n",
    "    \"\"\"Process data using multiple threads\"\"\"\n",
    "    chunk_size = len(data) // num_threads\n",
    "    threads = []\n",
    "    results = {}\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create and start threads\n",
    "    for i in range(num_threads):\n",
    "        start_idx = i * chunk_size\n",
    "        if i == num_threads - 1:  # Last thread gets remaining data\n",
    "            end_idx = len(data)\n",
    "        else:\n",
    "            end_idx = (i + 1) * chunk_size\n",
    "        \n",
    "        chunk = data[start_idx:end_idx]\n",
    "        thread = threading.Thread(\n",
    "            target=process_data_chunk,\n",
    "            args=(i, chunk, results, lock)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Combine results\n",
    "    final_result = []\n",
    "    for i in range(num_threads):\n",
    "        final_result.extend(results[i])\n",
    "    \n",
    "    print(f\"Parallel processing completed in {end_time - start_time:.2f} seconds\")\n",
    "    return final_result\n",
    "\n",
    "# Test parallel processing\n",
    "large_dataset = list(range(1, 101))  # 100 data points\n",
    "processed_data = parallel_data_processing(large_dataset, num_threads=4)\n",
    "print(f\"Processed {len(processed_data)} items\")\n",
    "print(f\"Sample results: {processed_data[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c73858-6aa9-4a3f-9bf1-38f4c8844f05",
   "metadata": {},
   "source": [
    "### Exercise 6.2: Concurrent Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d4e0c19-fdfd-44b0-b798-164b2748bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting concurrent model training...\n",
      "Starting training for Linear_Regression\n",
      "Starting training for Random_Forest\n",
      "Starting training for Neural_Network\n",
      "Linear_Regression - Epoch 1: Accuracy = 0.635\n",
      "Random_Forest - Epoch 1: Accuracy = 0.627\n",
      "Neural_Network - Epoch 1: Accuracy = 0.714\n",
      "Linear_Regression - Epoch 2: Accuracy = 0.885\n",
      "Random_Forest - Epoch 2: Accuracy = 0.712\n",
      "Neural_Network - Epoch 2: Accuracy = 0.707\n",
      "Linear_Regression - Epoch 3: Accuracy = 0.526\n",
      "Random_Forest - Epoch 3: Accuracy = 0.712\n",
      "Random_Forest training completed! Final accuracy: 0.712\n",
      "Neural_Network - Epoch 3: Accuracy = 0.642\n",
      "Linear_Regression - Epoch 4: Accuracy = 0.884\n",
      "Neural_Network - Epoch 4: Accuracy = 0.843\n",
      "Neural_Network - Epoch 5: Accuracy = 0.674\n",
      "Linear_Regression - Epoch 5: Accuracy = 0.588\n",
      "Linear_Regression training completed! Final accuracy: 0.885\n",
      "Neural_Network - Epoch 6: Accuracy = 0.775\n",
      "Neural_Network - Epoch 7: Accuracy = 0.579\n",
      "Neural_Network training completed! Final accuracy: 0.843\n",
      "\n",
      "All models trained in 0.74 seconds\n",
      "\n",
      "Final Results:\n",
      "Random_Forest: 0.712 accuracy in 3 epochs\n",
      "Linear_Regression: 0.885 accuracy in 5 epochs\n",
      "Neural_Network: 0.843 accuracy in 7 epochs\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Simulate concurrent model training\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.training_results = {}\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def train_model(self, model_name, training_data, epochs):\n",
    "        \"\"\"Train a model (simulated)\"\"\"\n",
    "        print(f\"Starting training for {model_name}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        for epoch in range(epochs):\n",
    "            # Simulate training time\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            # Simulate improving accuracy\n",
    "            accuracy = random.uniform(0.5, 0.9) + (epoch * 0.01)\n",
    "            accuracies.append(min(accuracy, 0.99))  # Cap at 99%\n",
    "            \n",
    "            print(f\"{model_name} - Epoch {epoch+1}: Accuracy = {accuracy:.3f}\")\n",
    "        \n",
    "        final_accuracy = max(accuracies)\n",
    "        \n",
    "        # Thread-safe storage of results\n",
    "        with self.lock:\n",
    "            self.training_results[model_name] = {\n",
    "                \"final_accuracy\": final_accuracy,\n",
    "                \"epochs\": epochs,\n",
    "                \"training_history\": accuracies\n",
    "            }\n",
    "        \n",
    "        print(f\"{model_name} training completed! Final accuracy: {final_accuracy:.3f}\")\n",
    "    \n",
    "    def train_multiple_models(self, models_config):\n",
    "        \"\"\"Train multiple models concurrently\"\"\"\n",
    "        threads = []\n",
    "        \n",
    "        for model_name, config in models_config.items():\n",
    "            thread = threading.Thread(\n",
    "                target=self.train_model,\n",
    "                args=(model_name, config[\"data\"], config[\"epochs\"])\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        \n",
    "        # Wait for all training to complete\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "        return self.training_results\n",
    "\n",
    "# Test concurrent model training\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "models_to_train = {\n",
    "    \"Linear_Regression\": {\"data\": \"dataset_1\", \"epochs\": 5},\n",
    "    \"Random_Forest\": {\"data\": \"dataset_2\", \"epochs\": 3},\n",
    "    \"Neural_Network\": {\"data\": \"dataset_3\", \"epochs\": 7}\n",
    "}\n",
    "\n",
    "print(\"Starting concurrent model training...\")\n",
    "start_time = time.time()\n",
    "results = trainer.train_multiple_models(models_to_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nAll models trained in {end_time - start_time:.2f} seconds\")\n",
    "print(\"\\nFinal Results:\")\n",
    "for model, result in results.items():\n",
    "    print(f\"{model}: {result['final_accuracy']:.3f} accuracy in {result['epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851dc66f-30c0-4d6b-a504-cab05cb33d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
